# run_recon_pipeline.py
"""
Tri-Source Reconciliation Pipeline - ìš´ì˜ ë°°ì„  (ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸)
HVDC SKU Master Hub Enhanced Systemì˜ í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import sys
import os
from pathlib import Path
from datetime import datetime
import argparse
import json

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from recon.reconciliation_engine import run_reconciliation, validate_reconciliation_inputs
from recon.exceptions_bridge import run_exceptions_bridge_pipeline
from config.recon_settings import get_config, validate_config

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="HVDC Tri-Source Reconciliation Pipeline")
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument("--hitachi", required=True, help="HITACHI íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--siemens", required=True, help="SIEMENS íŒŒì¼ ê²½ë¡œ") 
    parser.add_argument("--stock", required=True, help="Stock íŒŒì¼ ê²½ë¡œ")
    
    # ì„ íƒ ì¸ì
    parser.add_argument("--invoice", help="Invoice ëŒ€ì‹œë³´ë“œ Excel íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--out-dir", default="out", help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: out)")
    parser.add_argument("--environment", default="dev", choices=["dev", "staging", "prod"], help="í™˜ê²½ ì„¤ì •")
    parser.add_argument("--skip-exceptions", action="store_true", help="ì˜ˆì™¸ ë¸Œë¦¬ì§€ ìŠ¤í‚µ")
    parser.add_argument("--config-file", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON)")
    parser.add_argument("--validate-only", action="store_true", help="ì…ë ¥ ê²€ì¦ë§Œ ìˆ˜í–‰")
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("ğŸš€ HVDC Tri-Source Reconciliation Pipeline")
    print("=" * 70)
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸŒ í™˜ê²½: {args.environment}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.out_dir}")
    
    # 1) ì„¤ì • ë¡œë“œ
    print(f"\nâš™ï¸ Step 1: ì„¤ì • ë¡œë“œ")
    print("-" * 40)
    
    if args.config_file and Path(args.config_file).exists():
        with open(args.config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"âœ… ì‚¬ìš©ì ì„¤ì • ë¡œë“œ: {args.config_file}")
    else:
        config = get_config(args.environment)
        print(f"âœ… ê¸°ë³¸ ì„¤ì • ë¡œë“œ: {args.environment}")
    
    # ì„¤ì • ê²€ì¦
    validation = validate_config(config)
    if not validation["valid"]:
        print(f"âŒ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {validation['errors']}")
        return 1
    
    if validation["warnings"]:
        print(f"âš ï¸ ì„¤ì • ê²½ê³ : {validation['warnings']}")
    
    # 2) ì…ë ¥ íŒŒì¼ ê²€ì¦
    print(f"\nğŸ” Step 2: ì…ë ¥ íŒŒì¼ ê²€ì¦")
    print("-" * 40)
    
    input_validation = validate_reconciliation_inputs(
        args.hitachi, args.siemens, args.stock, args.invoice
    )
    
    print(f"ğŸ“Š ê²€ì¦ ê²°ê³¼:")
    for file_type, info in input_validation.items():
        if isinstance(info, dict) and "exists" in info:
            status = "âœ…" if info["exists"] else "âŒ"
            print(f"  {status} {file_type}: {info['path']}")
    
    if not input_validation["validation_passed"]:
        print("âŒ ì…ë ¥ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨")
        return 1
    
    if args.validate_only:
        print("âœ… ì…ë ¥ ê²€ì¦ ì™„ë£Œ (ê²€ì¦ë§Œ ìˆ˜í–‰)")
        return 0
    
    # 3) ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    print(f"\nğŸ“ Step 3: ì¶œë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„")
    print("-" * 40)
    
    Path(args.out_dir).mkdir(parents=True, exist_ok=True)
    print(f"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {args.out_dir}")
    
    # 4) Tri-Source Reconciliation ì‹¤í–‰
    print(f"\nğŸ”„ Step 4: Tri-Source Reconciliation ì‹¤í–‰")
    print("-" * 40)
    
    try:
        pq, kpi = run_reconciliation(
            hitachi_file=args.hitachi,
            siemens_file=args.siemens,
            stock_file=args.stock,
            invoice_dashboard_xlsx=args.invoice,
            out_dir=args.out_dir
        )
        
        print(f"âœ… Reconciliation ì™„ë£Œ: {pq}")
        
    except Exception as e:
        print(f"âŒ Reconciliation ì‹¤íŒ¨: {e}")
        return 1
    
    # 5) ì˜ˆì™¸ ë¸Œë¦¬ì§€ ì‹¤í–‰ (ì„ íƒì )
    if not args.skip_exceptions and args.invoice:
        print(f"\nğŸ”— Step 5: ì˜ˆì™¸â†’SKU ë¸Œë¦¬ì§€ ì‹¤í–‰")
        print("-" * 40)
        
        try:
            exceptions_result = run_exceptions_bridge_pipeline(
                invoice_dashboard_xlsx=args.invoice,
                sku_master_parquet=pq,
                out_dir=args.out_dir
            )
            
            if exceptions_result["success"]:
                print(f"âœ… ì˜ˆì™¸ ë¸Œë¦¬ì§€ ì™„ë£Œ")
            else:
                print(f"âš ï¸ ì˜ˆì™¸ ë¸Œë¦¬ì§€ ì‹¤íŒ¨: {exceptions_result.get('error', 'Unknown error')}")
                
        except Exception as e:
            print(f"âš ï¸ ì˜ˆì™¸ ë¸Œë¦¬ì§€ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # 6) ìµœì¢… ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š Step 6: ìµœì¢… ê²°ê³¼ ìš”ì•½")
    print("-" * 40)
    
    # KPI ìš”ì•½
    print(f"ğŸ“ˆ ì²˜ë¦¬ í†µê³„:")
    print(f"  - ì´ ë ˆì½”ë“œ: {kpi['total_records']:,}")
    print(f"  - ê³ ìœ  SKU: {kpi['unique_skus']:,}")
    print(f"  - ì‹¤í–‰ ì‹œê°„: {kpi['execution_time']:.2f}ì´ˆ")
    print(f"  - Flow ì»¤ë²„ë¦¬ì§€: {kpi['flow_coverage']}ê°œ ì½”ë“œ")
    print(f"  - ìœ„ì¹˜ ì»¤ë²„ë¦¬ì§€: {kpi['location_coverage']}ê°œ ìœ„ì¹˜")
    
    if kpi.get("invoice_pass_rate") is not None:
        print(f"  - Invoice í†µê³¼ìœ¨: {kpi['invoice_pass_rate']:.1%}")
    
    # ë°ì´í„° ì†ŒìŠ¤ë³„ í†µê³„
    if "data_sources" in kpi:
        print(f"ğŸ“Š ë°ì´í„° ì†ŒìŠ¤ë³„ í†µê³„:")
        for source, count in kpi["data_sources"].items():
            print(f"  - {source}: {count:,} ê±´")
    
    # ì¶œë ¥ íŒŒì¼ ëª©ë¡
    output_files = [
        ("SKU Master Parquet", pq),
        ("SKU Master DuckDB", pq.replace(".parquet", ".duckdb")),
    ]
    
    if not args.skip_exceptions and args.invoice:
        output_files.extend([
            ("Exceptions by SKU Parquet", f"{args.out_dir}/exceptions_by_sku.parquet"),
            ("Exceptions Report", f"{args.out_dir}/exceptions_report.xlsx")
        ])
    
    print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    for file_type, file_path in output_files:
        if Path(file_path).exists():
            size_mb = Path(file_path).stat().st_size / (1024 * 1024)
            print(f"  âœ… {file_type}: {file_path} ({size_mb:.1f}MB)")
        else:
            print(f"  âŒ {file_type}: {file_path} (ì—†ìŒ)")
    
    # ì‹¤í–‰ ë¡œê·¸ ì €ì¥ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜)
    def convert_for_json(obj):
        """JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ numpy íƒ€ì… ë³€í™˜"""
        import numpy as np
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {key: convert_for_json(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [convert_for_json(item) for item in obj]
        else:
            return obj
    
    log_data = {
        "timestamp": datetime.now().isoformat(),
        "environment": args.environment,
        "input_files": {
            "hitachi": args.hitachi,
            "siemens": args.siemens,
            "stock": args.stock,
            "invoice": args.invoice
        },
        "output_directory": args.out_dir,
        "kpi": convert_for_json(kpi),
        "config": convert_for_json(config)
    }
    
    log_file = f"{args.out_dir}/pipeline_execution_log.json"
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ ì‹¤í–‰ ë¡œê·¸: {log_file}")
    
    print("\n" + "=" * 70)
    print("ğŸ‰ HVDC Tri-Source Reconciliation Pipeline ì™„ë£Œ!")
    print("=" * 70)
    
    return 0

def run_quick_test():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê°œë°œìš©)"""
    print("ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    # ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
    test_files = {
        "hitachi": "HVDC_excel_reporter_final_sqm_rev.xlsx",
        "siemens": "HVDC_excel_reporter_final_sqm_rev.xlsx",
        "stock": "HVDC_Stock On Hand Report (1).xlsx",
        "invoice": None  # ì„ íƒì 
    }
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    for file_type, file_path in test_files.items():
        if file_path and Path(file_path).exists():
            print(f"âœ… {file_type}: {file_path}")
        elif file_path:
            print(f"âŒ {file_type}: {file_path} (ì—†ìŒ)")
        else:
            print(f"âš ï¸ {file_type}: ì„ íƒì  (None)")
    
    # ì…ë ¥ ê²€ì¦ë§Œ ì‹¤í–‰
    validation = validate_reconciliation_inputs(
        test_files["hitachi"], 
        test_files["siemens"], 
        test_files["stock"], 
        test_files["invoice"]
    )
    
    print(f"\nê²€ì¦ ê²°ê³¼: {'âœ… í†µê³¼' if validation['validation_passed'] else 'âŒ ì‹¤íŒ¨'}")
    return validation["validation_passed"]

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìê°€ ì—†ìœ¼ë©´ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if len(sys.argv) == 1:
        success = run_quick_test()
        sys.exit(0 if success else 1)
    
    # ì •ìƒ ì‹¤í–‰
    exit_code = main()
    sys.exit(exit_code)
