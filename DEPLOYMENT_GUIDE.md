# HVDC SKU Master Hub - ë°°í¬ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” HVDC SKU Master Hub v2.0 ì‹œìŠ¤í…œì˜ ì„¤ì¹˜, ì„¤ì •, ìš´ì˜ ë°©ë²•ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ› ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### 1. í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
```
ğŸ’» ìµœì†Œ ìš”êµ¬ì‚¬í•­:
â”œâ”€â”€ CPU: Intel i5 ë˜ëŠ” ë™ë“±í•œ ì„±ëŠ¥
â”œâ”€â”€ RAM: 8GB (ê¶Œì¥ 16GB)
â”œâ”€â”€ Storage: 10GB ì—¬ìœ  ê³µê°„
â””â”€â”€ Network: ì¸í„°ë„· ì—°ê²° (AWS ë°°í¬ì‹œ)

ğŸ’» ê¶Œì¥ ìš”êµ¬ì‚¬í•­:
â”œâ”€â”€ CPU: Intel i7 ë˜ëŠ” ë™ë“±í•œ ì„±ëŠ¥
â”œâ”€â”€ RAM: 16GB (ê¶Œì¥ 32GB)
â”œâ”€â”€ Storage: 50GB SSD ì—¬ìœ  ê³µê°„
â””â”€â”€ Network: ì•ˆì •ì ì¸ ì¸í„°ë„· ì—°ê²°
```

### 2. ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
```
ğŸ Python í™˜ê²½:
â”œâ”€â”€ Python: 3.11+ (í…ŒìŠ¤íŠ¸: 3.12.4)
â”œâ”€â”€ pip: ìµœì‹  ë²„ì „
â””â”€â”€ ê°€ìƒí™˜ê²½ ê¶Œì¥ (venv, conda)

ğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€:
â”œâ”€â”€ pandas: 2.3.2+
â”œâ”€â”€ duckdb: 1.4.0+
â”œâ”€â”€ openpyxl: ìµœì‹  ë²„ì „
â”œâ”€â”€ numpy: ìµœì‹  ë²„ì „
â””â”€â”€ pytest: í…ŒìŠ¤íŠ¸ìš© (ì„ íƒì )
```

## ğŸ“¦ ì„¤ì¹˜ ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •

#### 1.1 Python ê°€ìƒí™˜ê²½ ìƒì„±
```bash
# Windows
python -m venv hvdc_env
hvdc_env\Scripts\activate

# Linux/Mac
python3 -m venv hvdc_env
source hvdc_env/bin/activate
```

#### 1.2 í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install pandas duckdb openpyxl numpy pytest

# ë˜ëŠ” requirements.txt ì‚¬ìš© (ìƒì„± ì˜ˆì •)
pip install -r requirements.txt
```

### 2. í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸

```
ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°:
Stock/
â”œâ”€â”€ adapters (1)/                    # ë°ì´í„° ì–´ëŒ‘í„°
â”‚   â”œâ”€â”€ invoice_adapter (1).py       # Invoice ì²˜ë¦¬
â”‚   â”œâ”€â”€ reporter_adapter_v2.py       # Reporter v2 (ìƒˆë¡œì›€)
â”‚   â””â”€â”€ stock_adapter_v2.py          # Stock v2 (ìƒˆë¡œì›€)
â”œâ”€â”€ hub (1)/                         # SKU Master Hub
â”‚   â”œâ”€â”€ sku_master (1).py            # ì›ë³¸ Hub
â”‚   â””â”€â”€ sku_master_v2.py             # Hub v2 (ìƒˆë¡œì›€)
â”œâ”€â”€ recon/                           # Reconciliation ì—”ì§„
â”‚   â”œâ”€â”€ reconciliation_engine.py     # ì‚¼ì¤‘ ëŒ€ì¡° ì—”ì§„
â”‚   â””â”€â”€ exceptions_bridge.py         # ì˜ˆì™¸ ë¸Œë¦¬ì§€
â”œâ”€â”€ config/                          # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ recon_settings.py            # í†µí•© ì„¤ì •
â”œâ”€â”€ enhanced_sku_utils.py            # í•µì‹¬ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ run_recon_pipeline.py            # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ test_enhanced_features.py        # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
â””â”€â”€ ë°ì´í„° íŒŒì¼ë“¤...
```

### 3. ë°ì´í„° íŒŒì¼ ì¤€ë¹„

#### 3.1 í•„ìˆ˜ ë°ì´í„° íŒŒì¼
```
ğŸ“Š í•„ìˆ˜ íŒŒì¼:
â”œâ”€â”€ HVDC_excel_reporter_final_sqm_rev.xlsx    # HITACHI/SIEMENS ë°ì´í„°
â”œâ”€â”€ HVDC_Stock On Hand Report (1).xlsx        # Stock ë°ì´í„°
â””â”€â”€ HVDC_Invoice.xlsx                         # Invoice ë°ì´í„° (ì„ íƒì )
```

#### 3.2 íŒŒì¼ ê²€ì¦
```bash
# íŒŒì¼ ì¡´ì¬ í™•ì¸
python -c "
import os
files = [
    'HVDC_excel_reporter_final_sqm_rev.xlsx',
    'HVDC_Stock On Hand Report (1).xlsx'
]
for f in files:
    print(f'âœ… {f}: {os.path.exists(f)}')
"
```

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 1. ë¹ ë¥¸ ì‹œì‘

#### 1.1 ê¸°ë³¸ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸)
```bash
# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python run_recon_pipeline.py

# ê²°ê³¼ í™•ì¸
ls -la out_recon/
```

#### 1.2 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```bash
# ì „ì²´ Tri-Source Reconciliation ì‹¤í–‰
python run_recon_pipeline.py \
  --hitachi "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --siemens "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --stock "HVDC_Stock On Hand Report (1).xlsx" \
  --out-dir "out_recon"
```

### 2. ê³ ê¸‰ ì‹¤í–‰ ì˜µì…˜

#### 2.1 í™˜ê²½ë³„ ì‹¤í–‰
```bash
# ê°œë°œ í™˜ê²½
python run_recon_pipeline.py \
  --hitachi "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --siemens "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --stock "HVDC_Stock On Hand Report (1).xlsx" \
  --environment dev \
  --out-dir "out_dev"

# ìš´ì˜ í™˜ê²½
python run_recon_pipeline.py \
  --hitachi "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --siemens "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --stock "HVDC_Stock On Hand Report (1).xlsx" \
  --environment prod \
  --out-dir "out_prod"
```

#### 2.2 Invoice ë°ì´í„° í¬í•¨ ì‹¤í–‰
```bash
# Invoice ë°ì´í„° í¬í•¨
python run_recon_pipeline.py \
  --hitachi "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --siemens "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --stock "HVDC_Stock On Hand Report (1).xlsx" \
  --invoice "HVDC_Invoice_Validation_Dashboard.xlsx" \
  --out-dir "out_full"
```

### 3. ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰

#### 3.1 ì˜ˆì™¸ ë¸Œë¦¬ì§€ ì‹¤í–‰
```bash
# ì˜ˆì™¸â†’SKU ë¸Œë¦¬ì§€ ì‹¤í–‰
python recon/exceptions_bridge.py

# ë˜ëŠ” íŒŒì´í”„ë¼ì¸ì—ì„œ ìë™ ì‹¤í–‰
python run_recon_pipeline.py --skip-exceptions=false
```

#### 3.2 í–¥ìƒëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```bash
# ê¸°ì¡´ Enhanced Pipeline ì‹¤í–‰
python run_enhanced_pipeline.py

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_enhanced_features.py
```

## âš™ï¸ ì„¤ì • ë° êµ¬ì„±

### 1. ì„¤ì • íŒŒì¼ ìˆ˜ì •

#### 1.1 ê¸°ë³¸ ì„¤ì • (config/recon_settings.py)
```python
# í†¨ëŸ¬ëŸ°ìŠ¤ ì„¤ì • ìˆ˜ì •
INVOICE_MATCHING = {
    "tolerance": {
        "default": 0.10,    # ê¸°ë³¸ Â±10% â†’ í•„ìš”ì‹œ ì¡°ì •
        "HE": 0.10,         # HITACHI í†¨ëŸ¬ëŸ°ìŠ¤
        "SIM": 0.15         # SIEMENS í†¨ëŸ¬ëŸ°ìŠ¤
    }
}

# í™˜ê²½ë³„ ì„¤ì •
ENVIRONMENT_CONFIGS = {
    "prod": {
        "debug": False,              # ìš´ì˜ì‹œ False
        "save_intermediate": False,   # ì¤‘ê°„ íŒŒì¼ ì €ì¥ ì•ˆí•¨
        "notification_enabled": True  # ì•Œë¦¼ í™œì„±í™”
    }
}
```

#### 1.2 ì‚¬ìš©ì ì •ì˜ ì„¤ì • íŒŒì¼
```bash
# ì‚¬ìš©ì ì„¤ì • íŒŒì¼ ìƒì„±
cp config/recon_settings.py config/my_settings.py

# ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
python run_recon_pipeline.py \
  --config-file "config/my_settings.py" \
  [ê¸°íƒ€ ì˜µì…˜ë“¤...]
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

#### 2.1 DuckDB ì„¤ì •
```python
# config/recon_settings.py
DUCKDB_CONFIG = {
    "memory_limit": "2GB",      # ë©”ëª¨ë¦¬ ì œí•œ
    "threads": 4,               # ìŠ¤ë ˆë“œ ìˆ˜
    "max_memory": "4GB",        # ìµœëŒ€ ë©”ëª¨ë¦¬
    "temp_directory": "out/temp" # ì„ì‹œ ë””ë ‰í† ë¦¬
}
```

#### 2.2 ì¶œë ¥ ì„¤ì •
```python
OUTPUT_CONFIG = {
    "parquet_compression": "snappy",  # ì••ì¶• ë°©ì‹
    "include_metadata": True,         # ë©”íƒ€ë°ì´í„° í¬í•¨
    "save_intermediate": True,        # ì¤‘ê°„ íŒŒì¼ ì €ì¥
    "backup_previous": True,          # ì´ì „ ë²„ì „ ë°±ì—…
    "max_backup_files": 5             # ìµœëŒ€ ë°±ì—… íŒŒì¼ ìˆ˜
}
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 1. ì‹¤í–‰ ë¡œê·¸ í™•ì¸

#### 1.1 ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜
```
ğŸ“ ë¡œê·¸ íŒŒì¼:
â”œâ”€â”€ out_recon/pipeline_execution_log.json    # ì‹¤í–‰ ë¡œê·¸
â”œâ”€â”€ console output                           # ì½˜ì†” ì¶œë ¥
â””â”€â”€ DuckDB ë‚´ë¶€ ë¡œê·¸                         # ë°ì´í„°ë² ì´ìŠ¤ ë¡œê·¸
```

#### 1.2 ë¡œê·¸ ë¶„ì„
```bash
# ì‹¤í–‰ ë¡œê·¸ í™•ì¸
cat out_recon/pipeline_execution_log.json | jq '.'

# íŠ¹ì • ì •ë³´ ì¶”ì¶œ
cat out_recon/pipeline_execution_log.json | jq '.kpi.total_records'
cat out_recon/pipeline_execution_log.json | jq '.kpi.execution_time'
```

### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

#### 2.1 ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
```bash
# ì‹œê°„ ì¸¡ì • ì‹¤í–‰
time python run_recon_pipeline.py \
  --hitachi "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --siemens "HVDC_excel_reporter_final_sqm_rev.xlsx" \
  --stock "HVDC_Stock On Hand Report (1).xlsx"
```

#### 2.2 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
import psutil
import time

def monitor_memory():
    process = psutil.Process()
    while True:
        memory_mb = process.memory_info().rss / 1024 / 1024
        print(f"Memory usage: {memory_mb:.1f} MB")
        time.sleep(5)

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
monitor_memory()
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

#### 1.1 ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -m pytest test_enhanced_features.py -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
python -m pytest test_enhanced_features.py::TestFlowTransitions -v
```

#### 1.2 ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
```bash
# SKU ì •ê·œí™” í…ŒìŠ¤íŠ¸
python -c "
from enhanced_sku_utils import normalize_sku
test_cases = ['sku-001', 'SKU 002', 'sku003']
for case in test_cases:
    print(f'{case} -> {normalize_sku(case)}')
"

# Flow ì „ì´ ê²€ì¦ í…ŒìŠ¤íŠ¸
python -c "
from enhanced_sku_utils import validate_flow_transitions
import pandas as pd
# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ë° ê²€ì¦
"
```

### 2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦

#### 2.1 ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
```bash
# DuckDBë¥¼ í†µí•œ ë°ì´í„° í™•ì¸
duckdb out_recon/sku_master_v2.duckdb

# SQL ì¿¼ë¦¬ ì‹¤í–‰
SELECT COUNT(*) as total_records FROM sku_master;
SELECT flow_code, COUNT(*) FROM sku_master GROUP BY flow_code;
SELECT Final_Location, COUNT(*) FROM sku_master GROUP BY Final_Location;
```

#### 2.2 ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸
```python
# í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
python -c "
from hub.sku_master_v2 import get_hub_statistics
import pandas as pd

# ë°ì´í„° ë¡œë“œ
df = pd.read_parquet('out_recon/SKU_MASTER_v2.parquet')

# í†µê³„ ìƒì„±
stats = get_hub_statistics(df)
print('Data Quality Report:')
for key, value in stats.items():
    print(f'  {key}: {value}')
"
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### 1. ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1.1 ëª¨ë“ˆ Import ì˜¤ë¥˜
```bash
# ë¬¸ì œ: ModuleNotFoundError
# í•´ê²°: Python ê²½ë¡œ í™•ì¸
python -c "import sys; print('\\n'.join(sys.path))"

# í•´ê²°: í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
cd /path/to/Stock
python run_recon_pipeline.py
```

#### 1.2 íŒŒì¼ ê²½ë¡œ ë¬¸ì œ
```bash
# ë¬¸ì œ: FileNotFoundError
# í•´ê²°: íŒŒì¼ ì¡´ì¬ í™•ì¸
ls -la *.xlsx

# í•´ê²°: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
python run_recon_pipeline.py \
  --hitachi "/full/path/to/HVDC_excel_reporter_final_sqm_rev.xlsx" \
  [ê¸°íƒ€ ì˜µì…˜ë“¤...]
```

#### 1.3 ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë¬¸ì œ: MemoryError
# í•´ê²°: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
# config/recon_settings.py ìˆ˜ì •
DUCKDB_CONFIG = {
    "memory_limit": "1GB",  # 2GB â†’ 1GBë¡œ ì¤„ì´ê¸°
    "threads": 2            # 4 â†’ 2ë¡œ ì¤„ì´ê¸°
}
```

### 2. ì„±ëŠ¥ ìµœì í™”

#### 2.1 ì²˜ë¦¬ ì†ë„ ê°œì„ 
```python
# config/recon_settings.py
OUTPUT_CONFIG = {
    "parquet_compression": "zstd",  # snappy â†’ zstd (ë” ë¹ ë¦„)
    "save_intermediate": False,     # ì¤‘ê°„ íŒŒì¼ ì €ì¥ ì•ˆí•¨
}

DUCKDB_CONFIG = {
    "threads": 8,              # CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì¡°ì •
    "memory_limit": "4GB",     # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì˜ 50% ì •ë„
}
```

#### 2.2 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ì‹œ
import gc

def process_large_dataset():
    # ë°ì´í„° ì²˜ë¦¬
    result = process_data()
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gc.collect()
    
    return result
```

## ğŸ“ˆ ìš´ì˜ ëª¨ë“œ

### 1. ìŠ¤ì¼€ì¤„ë§ ì‹¤í–‰

#### 1.1 Windows Task Scheduler
```batch
@echo off
cd /d "C:\Stock"
python run_recon_pipeline.py ^
  --hitachi "HVDC_excel_reporter_final_sqm_rev.xlsx" ^
  --siemens "HVDC_excel_reporter_final_sqm_rev.xlsx" ^
  --stock "HVDC_Stock On Hand Report (1).xlsx" ^
  --environment prod ^
  --out-dir "out_prod"
```

#### 1.2 Linux Cron Job
```bash
# crontab -e
# ë§¤ì¼ ì˜¤ì „ 2ì‹œ ì‹¤í–‰
0 2 * * * cd /path/to/Stock && python run_recon_pipeline.py --hitachi "HVDC_excel_reporter_final_sqm_rev.xlsx" --siemens "HVDC_excel_reporter_final_sqm_rev.xlsx" --stock "HVDC_Stock On Hand Report (1).xlsx" --environment prod --out-dir "out_prod"
```

### 2. ë°±ì—… ë° ë³µêµ¬

#### 2.1 ìë™ ë°±ì—… ì„¤ì •
```python
# config/recon_settings.py
OUTPUT_CONFIG = {
    "backup_previous": True,
    "max_backup_files": 7,  # 7ì¼ì¹˜ ë°±ì—… ìœ ì§€
    "backup_location": "backups/"
}
```

#### 2.2 ìˆ˜ë™ ë°±ì—…
```bash
# ë°ì´í„° ë°±ì—…
cp -r out_recon/ backups/$(date +%Y%m%d)/

# íŠ¹ì • ë‚ ì§œ ë³µêµ¬
cp -r backups/20240920/ out_recon/
```

## ğŸš€ AWS í´ë¼ìš°ë“œ ë°°í¬ (ì„ íƒì )

### 1. AWS SAM ë°°í¬

#### 1.1 SAM ì„¤ì¹˜
```bash
# AWS CLI ì„¤ì¹˜
aws --version

# SAM CLI ì„¤ì¹˜
pip install aws-sam-cli
sam --version
```

#### 1.2 ë°°í¬ ì‹¤í–‰
```bash
# SAM ë¹Œë“œ
cd aws
sam build

# ë°°í¬ (ê°€ì´ë“œ ëª¨ë“œ)
sam deploy --guided

# ë°°í¬ (ìë™ ëª¨ë“œ)
sam deploy
```

### 2. Lambda í•¨ìˆ˜ ë°°í¬

#### 2.1 ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œ
```bash
# BERTopic Lambda
cd aws/lambda_bertopic
docker build -t bertopic-lambda .

# SKU Hub Lambda
cd aws/lambda_sku_hub
docker build -t sku-hub-lambda .
```

#### 2.2 ECR í‘¸ì‹œ
```bash
# ECR ë¡œê·¸ì¸
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin [account-id].dkr.ecr.us-east-1.amazonaws.com

# ì´ë¯¸ì§€ í‘¸ì‹œ
docker tag bertopic-lambda:latest [account-id].dkr.ecr.us-east-1.amazonaws.com/bertopic-lambda:latest
docker push [account-id].dkr.ecr.us-east-1.amazonaws.com/bertopic-lambda:latest
```

## ğŸ“ ì§€ì› ë° ë¬¸ì˜

### 1. ë¡œê·¸ ìˆ˜ì§‘
```bash
# ë¬¸ì œ ë°œìƒì‹œ ë¡œê·¸ ìˆ˜ì§‘
mkdir troubleshooting_logs
cp out_recon/pipeline_execution_log.json troubleshooting_logs/
cp out_recon/sku_master_v2.duckdb troubleshooting_logs/
python -c "import sys; print(sys.version)" > troubleshooting_logs/python_version.txt
```

### 2. ì„±ëŠ¥ ë¦¬í¬íŠ¸
```bash
# ì„±ëŠ¥ ì •ë³´ ìˆ˜ì§‘
python -c "
import pandas as pd
import duckdb
import os

print('=== System Information ===')
print(f'Python version: {sys.version}')
print(f'Pandas version: {pd.__version__}')
print(f'DuckDB version: {duckdb.__version__}')

print('\\n=== File Sizes ===')
files = ['out_recon/SKU_MASTER_v2.parquet', 'out_recon/sku_master_v2.duckdb']
for f in files:
    if os.path.exists(f):
        size_mb = os.path.getsize(f) / 1024 / 1024
        print(f'{f}: {size_mb:.1f} MB')
"
```

---

## ğŸ“ ê²°ë¡ 

ì´ ë°°í¬ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ë©´ HVDC SKU Master Hub v2.0ì„ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜í•˜ê³  ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

**ì£¼ìš” íŠ¹ì§•:**
- âœ… ê°„ë‹¨í•œ ì„¤ì¹˜ ë° ì‹¤í–‰
- âœ… ìœ ì—°í•œ ì„¤ì • ì˜µì…˜
- âœ… í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
- âœ… ìƒì„¸í•œ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ
- âœ… AWS í´ë¼ìš°ë“œ ë°°í¬ ì§€ì›

**ì§€ì›ë˜ëŠ” ìš´ì˜ ëª¨ë“œ:**
- ğŸ–¥ï¸ ë¡œì»¬ ê°œë°œ í™˜ê²½
- ğŸ¢ ì˜¨í”„ë ˆë¯¸ìŠ¤ ìš´ì˜ í™˜ê²½
- â˜ï¸ AWS í´ë¼ìš°ë“œ í™˜ê²½

ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•œ ê²½ìš°, ì‹œìŠ¤í…œ ë¡œê·¸ì™€ í•¨ê»˜ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.
