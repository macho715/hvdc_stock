# recon/reconciliation_engine.py
"""
Tri-Source Reconciliation Engine - ì‚¼ì¤‘ ëŒ€ì¡° & DuckDB ì ì¬
Invoice â†” HVDC Excel(Flow/SQM) â†” Stock On-Hand(ìŠ¤ëƒ…ìƒ·) ì‚¼ì ëŒ€ì¡° í…Œì´ë¸” ìƒì„±
"""
import sys
import os
from pathlib import Path
import pandas as pd
import duckdb
from datetime import datetime
from typing import Dict, Any, Optional

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ê¸°ì¡´ ì–´ëŒ‘í„°ë“¤ import (ë™ì  ë¡œë“œ)
import importlib.util

def load_adapter_module(module_name, file_path):
    """ë™ì  ëª¨ë“ˆ ë¡œë“œ"""
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

# ì–´ëŒ‘í„° ëª¨ë“ˆ ë¡œë“œ
adapters_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'adapters (1)')
hub_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'hub (1)')

try:
    # v2 ì–´ëŒ‘í„°ë“¤ ì‹œë„
    reporter_adapter_v2 = load_adapter_module('reporter_adapter_v2', 
        os.path.join(adapters_dir, 'reporter_adapter_v2.py'))
    stock_adapter_v2 = load_adapter_module('stock_adapter_v2', 
        os.path.join(adapters_dir, 'stock_adapter_v2.py'))
    sku_master_v2 = load_adapter_module('sku_master_v2', 
        os.path.join(hub_dir, 'sku_master_v2.py'))
    
    compute_flow_and_sqm_v2 = reporter_adapter_v2.compute_flow_and_sqm_v2
    build_stock_snapshots_v2 = stock_adapter_v2.build_stock_snapshots_v2
    build_sku_master_v2 = sku_master_v2.build_sku_master_v2
    save_hub_v2 = sku_master_v2.save_hub_v2
    get_hub_statistics = sku_master_v2.get_hub_statistics
    
    print("[INFO] v2 adapters loaded successfully")
except Exception as e:
    print(f"[WARN] v2 adapters failed, using original: {e}")
    # fallback to original adapters
    reporter_adapter = load_adapter_module('reporter_adapter', 
        os.path.join(adapters_dir, 'reporter_adapter (1).py'))
    stock_adapter = load_adapter_module('stock_adapter', 
        os.path.join(adapters_dir, 'stock_adapter (1).py'))
    sku_master = load_adapter_module('sku_master', 
        os.path.join(hub_dir, 'sku_master (1).py'))
    
    compute_flow_and_sqm = reporter_adapter.compute_flow_and_sqm
    build_stock_snapshots = stock_adapter.build_stock_snapshots
    build_sku_master = sku_master.build_sku_master
    save_as_parquet_duckdb = sku_master.save_as_parquet_duckdb
    
    # v2 í•¨ìˆ˜ë“¤ì„ ì›ë³¸ìœ¼ë¡œ ì„¤ì • (fallback)
    compute_flow_and_sqm_v2 = compute_flow_and_sqm
    build_stock_snapshots_v2 = build_stock_snapshots
    build_sku_master_v2 = build_sku_master
    save_hub_v2 = save_as_parquet_duckdb
    get_hub_statistics = lambda df: {"total_records": len(df)}

def _read_invoice_dashboard(excel_path: str) -> pd.DataFrame:
    """
    ì¸ë³´ì´ìŠ¤ ê²€ì¦ ì—‘ì…€(HVDC_Invoice_Validation_Dashboard.xlsx)ì—ì„œ
    Exceptions_Only + Invoice_Original_Orderë¥¼ ì½ì–´ SKU ë§¤í•‘ í…Œì´ë¸” ìƒì„±
    
    Args:
        excel_path: Invoice ëŒ€ì‹œë³´ë“œ Excel íŒŒì¼ ê²½ë¡œ
    
    Returns:
        pd.DataFrame: Invoice ë§¤ì¹­ ê²°ê³¼
    """
    print(f"[INFO] Reading invoice dashboard: {excel_path}")
    
    try:
        xl = pd.ExcelFile(excel_path)
        print(f"[INFO] Available sheets: {xl.sheet_names}")
        
        # Exceptions_Only ì‹œíŠ¸ ì½ê¸°
        ex = pd.DataFrame()
        if "Exceptions_Only" in xl.sheet_names:
            ex = xl.parse("Exceptions_Only")
            print(f"[INFO] Exceptions_Only: {ex.shape}")
        
        # Invoice_Original_Order ì‹œíŠ¸ ì½ê¸° (ì£¼ìš” ë°ì´í„°)
        io = pd.DataFrame()
        if "Invoice_Original_Order" in xl.sheet_names:
            io = xl.parse("Invoice_Original_Order")
            print(f"[INFO] Invoice_Original_Order: {io.shape}")
        elif "Invoice_Original" in xl.sheet_names:
            io = xl.parse("Invoice_Original")
            print(f"[INFO] Invoice_Original: {io.shape}")
        
        # SKU ì»¬ëŸ¼ ì°¾ê¸°
        sku_col = None
        for c in ["Case No.", "SKU", "CaseNo", "Case_no", "HVDC CODE"]:
            if c in io.columns:
                sku_col = c
                break
        
        if sku_col is None:
            print("[WARN] No SKU column found in invoice data")
            io["SKU"] = None
        else:
            io = io.rename(columns={sku_col: "SKU"})
            print(f"[INFO] Using SKU column: {sku_col}")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬
        pick = ["SKU", "Match_Status", "GW_SumPicked", "CBM_SumPicked", "Err_GW", "Err_CBM"]
        for c in pick:
            if c not in io.columns:
                io[c] = None
        
        inv = io[pick].copy().drop_duplicates(subset=["SKU"])
        print(f"[INFO] Invoice data processed: {inv.shape}")
        
        return inv
        
    except Exception as e:
        print(f"[ERROR] Failed to read invoice dashboard: {e}")
        # ë¹ˆ DataFrame ë°˜í™˜
        return pd.DataFrame(columns=["SKU", "Match_Status", "GW_SumPicked", "CBM_SumPicked", "Err_GW", "Err_CBM"])

def run_reconciliation(
    hitachi_file: str,
    siemens_file: str,
    stock_file: str,
    invoice_dashboard_xlsx: Optional[str] = None,
    out_dir: str = "out"
) -> tuple:
    """
    Tri-Source Reconciliation ì‹¤í–‰
    
    Args:
        hitachi_file: HITACHI íŒŒì¼ ê²½ë¡œ
        siemens_file: SIEMENS íŒŒì¼ ê²½ë¡œ
        stock_file: Stock íŒŒì¼ ê²½ë¡œ
        invoice_dashboard_xlsx: Invoice ëŒ€ì‹œë³´ë“œ Excel íŒŒì¼ (ì„ íƒì )
        out_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    
    Returns:
        tuple: (parquet_path, kpi_dict)
    """
    print("=" * 60)
    print("ğŸš€ HVDC Tri-Source Reconciliation Engine Starting...")
    print("=" * 60)
    
    start_time = datetime.now()
    
    # 1) Reporter í†µê³„ (Flow/SQM ë“±)
    print("\nğŸ“Š Step 1: Reporter í†µê³„ ê³„ì‚°")
    print("-" * 40)
    try:
        rep_stats = compute_flow_and_sqm_v2(hitachi_file, siemens_file)
        print(f"âœ… Reporter ì™„ë£Œ: {rep_stats.get('total_records', 0)} ê±´")
    except Exception as e:
        print(f"âš ï¸ Reporter v2 ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
        rep_stats = compute_flow_and_sqm(hitachi_file, siemens_file)
        print(f"âœ… Reporter ì™„ë£Œ: {rep_stats.get('total_records', 0)} ê±´")

    # 2) Stock ìŠ¤ëƒ…ìƒ· (ìµœì‹ ì¼Â·íƒ€ì„ë¼ì¸Â·ìš”ì•½)
    print("\nğŸ“¦ Step 2: Stock ìŠ¤ëƒ…ìƒ· ìƒì„±")
    print("-" * 40)
    try:
        stock = build_stock_snapshots_v2(stock_file)
        print(f"âœ… Stock v2 ì™„ë£Œ: {stock['total_records']} ê±´, latest: {stock['latest_date']}")
    except Exception as e:
        print(f"âš ï¸ Stock v2 ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
        stock_result = build_stock_snapshots(stock_file)
        stock = {
            "summary_df": stock_result["summary_df"],
            "latest_date": None,
            "timeline": {},
            "total_records": len(stock_result["summary_df"])
        }
        print(f"âœ… Stock ì™„ë£Œ: {stock['total_records']} ê±´")

    # 3) Invoice ê²€ì¦ ê²°ê³¼ (ì„ íƒì )
    print("\nğŸ’° Step 3: Invoice ê²€ì¦ ê²°ê³¼ ì²˜ë¦¬")
    print("-" * 40)
    inv_df = None
    if invoice_dashboard_xlsx and Path(invoice_dashboard_xlsx).exists():
        inv_df = _read_invoice_dashboard(invoice_dashboard_xlsx)
        print(f"âœ… Invoice ì™„ë£Œ: {len(inv_df)} ê±´")
    else:
        print("âš ï¸ Invoice íŒŒì¼ ì—†ìŒ, SKUë§Œìœ¼ë¡œ ì§„í–‰")

    # 4) í—ˆë¸Œ êµ¬ì¶•
    print("\nğŸ¢ Step 4: SKU Master Hub êµ¬ì¶•")
    print("-" * 40)
    try:
        hub = build_sku_master_v2(
            stock_summary_df=stock["summary_df"],
            reporter_stats=rep_stats,
            invoice_match_df=inv_df
        )
        print(f"âœ… Hub v2 ì™„ë£Œ: {hub.shape}")
    except Exception as e:
        print(f"âš ï¸ Hub v2 ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
        hub = build_sku_master(
            stock["summary_df"], 
            rep_stats, 
            inv_df
        )
        print(f"âœ… Hub ì™„ë£Œ: {hub.shape}")

    # 5) ì €ì¥
    print("\nğŸ’¾ Step 5: ë°ì´í„° ì €ì¥")
    print("-" * 40)
    try:
        pq = save_hub_v2(hub, out_dir=out_dir, use_incremental=True)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {pq}")
    except Exception as e:
        print(f"âš ï¸ Hub v2 ì €ì¥ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
        pq = save_as_parquet_duckdb(hub, out_dir=out_dir, use_incremental=True)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {pq}")

    # 6) ì‚¼ì¤‘ ëŒ€ì¡° ìš”ì•½ (KPI)
    print("\nğŸ“ˆ Step 6: ì‚¼ì¤‘ ëŒ€ì¡° KPI ìƒì„±")
    print("-" * 40)
    kpi = {
        "execution_time": (datetime.now() - start_time).total_seconds(),
        "total_records": len(hub),
        "unique_skus": hub["SKU"].nunique(),
        "flow_coverage": hub["flow_code"].nunique() if "flow_code" in hub.columns else 0,
        "location_coverage": hub["Final_Location"].nunique() if "Final_Location" in hub.columns else 0,
        "vendor_distribution": hub["Vendor"].value_counts().to_dict() if "Vendor" in hub.columns else {},
        "data_sources": {
            "reporter_records": rep_stats.get("total_records", 0),
            "stock_records": stock["total_records"],
            "invoice_records": len(inv_df) if inv_df is not None else 0
        }
    }
    
    # Invoice í†µê³¼ìœ¨
    if "inv_match_status" in hub.columns:
        total_inv = hub["inv_match_status"].notna().sum()
        pass_inv = (hub["inv_match_status"] == "PASS").sum()
        kpi["invoice_pass_rate"] = pass_inv / total_inv if total_inv > 0 else 0
        kpi["invoice_fail_count"] = total_inv - pass_inv
    
    # Stock ìˆ˜ëŸ‰ ì»¤ë²„ë¦¬ì§€
    if "stock_qty" in hub.columns:
        kpi["stock_qty_coverage"] = hub["stock_qty"].notna().sum() / len(hub)
    
    # SQM ì»¤ë²„ë¦¬ì§€
    if "sku_sqm" in hub.columns:
        kpi["sqm_coverage"] = hub["sku_sqm"].notna().sum() / len(hub)

    # 7) DuckDB ë¶€ê°€ í…Œì´ë¸” ê¸°ë¡
    print("\nğŸ—„ï¸ Step 7: DuckDB ë¶€ê°€ í…Œì´ë¸” ìƒì„±")
    print("-" * 40)
    try:
        db = f"{out_dir}/sku_master_v2.duckdb" if Path(f"{out_dir}/sku_master_v2.duckdb").exists() else f"{out_dir}/sku_master.duckdb"
        con = duckdb.connect(db)
        
        # ì‚¼ì¤‘ ëŒ€ì¡° ìš”ì•½ í…Œì´ë¸”
        con.execute("CREATE OR REPLACE TABLE recon_summary AS SELECT * FROM hub", {"hub": hub})
        
        # Flow x Location ë·°
        con.execute("""
            CREATE OR REPLACE VIEW v_flow_location AS 
            SELECT Final_Location, flow_code, COUNT(*) AS n 
            FROM recon_summary 
            GROUP BY 1,2 
            ORDER BY 1,2
        """)
        
        # Invoice ì‹¤íŒ¨ ìƒìœ„ 20 SKU
        con.execute("""
            CREATE OR REPLACE VIEW v_invoice_failures_top20 AS
            SELECT SKU, inv_match_status, err_gw, err_cbm, GW, CBM
            FROM recon_summary
            WHERE inv_match_status <> 'PASS' OR inv_match_status IS NULL
            ORDER BY COALESCE(ABS(err_gw),0) + COALESCE(ABS(err_cbm),0) DESC
            LIMIT 20
        """)
        
        # ì‹¤í–‰ ë¡œê·¸ í…Œì´ë¸”
        run_log = pd.DataFrame([{
            "timestamp": start_time.isoformat(),
            "hitachi_file": hitachi_file,
            "siemens_file": siemens_file,
            "stock_file": stock_file,
            "invoice_file": invoice_dashboard_xlsx,
            "total_records": len(hub),
            "execution_time_seconds": kpi["execution_time"]
        }])
        
        con.execute("CREATE TABLE IF NOT EXISTS run_log (timestamp VARCHAR, hitachi_file VARCHAR, siemens_file VARCHAR, stock_file VARCHAR, invoice_file VARCHAR, total_records INTEGER, execution_time_seconds FLOAT)")
        con.execute("INSERT INTO run_log SELECT * FROM run_log_df", {"run_log_df": run_log})
        
        con.close()
        print("âœ… DuckDB ë¶€ê°€ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        print(f"âš ï¸ DuckDB ë¶€ê°€ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")

    # 8) ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ‰ Tri-Source Reconciliation ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {kpi['total_records']:,}")
    print(f"ğŸ•’ ì‹¤í–‰ ì‹œê°„: {kpi['execution_time']:.2f}ì´ˆ")
    print(f"ğŸ“ˆ Flow ì»¤ë²„ë¦¬ì§€: {kpi['flow_coverage']}ê°œ ì½”ë“œ")
    print(f"ğŸ¢ ìœ„ì¹˜ ì»¤ë²„ë¦¬ì§€: {kpi['location_coverage']}ê°œ ìœ„ì¹˜")
    
    if kpi.get("invoice_pass_rate") is not None:
        print(f"ğŸ’° Invoice í†µê³¼ìœ¨: {kpi['invoice_pass_rate']:.1%}")
    
    if kpi.get("stock_qty_coverage") is not None:
        print(f"ğŸ“¦ Stock ìˆ˜ëŸ‰ ì»¤ë²„ë¦¬ì§€: {kpi['stock_qty_coverage']:.1%}")
    
    if kpi.get("sqm_coverage") is not None:
        print(f"ğŸ“ SQM ì»¤ë²„ë¦¬ì§€: {kpi['sqm_coverage']:.1%}")
    
    print(f"\nğŸ“ ì¶œë ¥ íŒŒì¼: {pq}")
    print(f"ğŸ—„ï¸ DuckDB: {db}")
    
    return pq, kpi

def validate_reconciliation_inputs(
    hitachi_file: str,
    siemens_file: str, 
    stock_file: str,
    invoice_file: Optional[str] = None
) -> Dict[str, Any]:
    """
    Reconciliation ì…ë ¥ íŒŒì¼ ê²€ì¦
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    validation = {
        "hitachi_file": {"path": hitachi_file, "exists": Path(hitachi_file).exists()},
        "siemens_file": {"path": siemens_file, "exists": Path(siemens_file).exists()},
        "stock_file": {"path": stock_file, "exists": Path(stock_file).exists()},
        "invoice_file": {"path": invoice_file, "exists": Path(invoice_file).exists() if invoice_file else False},
        "all_required_exist": True,
        "validation_passed": True
    }
    
    # í•„ìˆ˜ íŒŒì¼ ê²€ì¦
    required_files = [hitachi_file, siemens_file, stock_file]
    for file_path in required_files:
        if not Path(file_path).exists():
            validation["all_required_exist"] = False
            validation["validation_passed"] = False
    
    return validation

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("Tri-Source Reconciliation Engine - í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
    hitachi_file = "HVDC_excel_reporter_final_sqm_rev.xlsx"
    siemens_file = "HVDC_excel_reporter_final_sqm_rev.xlsx"
    stock_file = "HVDC_Stock On Hand Report (1).xlsx"
    invoice_file = None  # "HVDC_Invoice_Validation_Dashboard.xlsx"
    
    # ì…ë ¥ ê²€ì¦
    validation = validate_reconciliation_inputs(hitachi_file, siemens_file, stock_file, invoice_file)
    print("ì…ë ¥ ê²€ì¦ ê²°ê³¼:", validation)
    
    if validation["validation_passed"]:
        try:
            pq, kpi = run_reconciliation(hitachi_file, siemens_file, stock_file, invoice_file)
            print(f"\nâœ… Reconciliation ì™„ë£Œ: {pq}")
            print(f"ğŸ“Š KPI: {kpi}")
        except Exception as e:
            print(f"âŒ Reconciliation ì‹¤íŒ¨: {e}")
    else:
        print("âŒ ì…ë ¥ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨")
